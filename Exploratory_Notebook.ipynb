{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--gpu'], dest='gpu', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='GPU id to use.', metavar=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Pose Estimation Training')\n",
    "# parser.add_argument('data', default='./data', metavar='DIR',\n",
    "#                     help='path to dataset')\n",
    "# parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "#                     help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=50, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "# parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "#                     metavar='N', help='mini-batch size (default: 256)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=25, type=int,\n",
    "                    metavar='N', help='print frequency (default: 25)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "# parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "#                     help='evaluate model on validation set')\n",
    "# # parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "# #                     help='use pre-trained model')\n",
    "# # parser.add_argument('--world-size', default=1, type=int,\n",
    "# #                     help='number of distributed processes')\n",
    "# # parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
    "# #                     help='url used to set up distributed training')\n",
    "# # parser.add_argument('--dist-backend', default='gloo', type=str,\n",
    "# #                     help='distributed backend')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--gpu', default=0, type=int,\n",
    "                    help='GPU id to use.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    The Leeds sport pose dataset.\n",
    "    (http://sam.johnson.io/research/lsp.html.)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    split : {'train', 'test'}\n",
    "    \"\"\"\n",
    "    def __init__(self, split):\n",
    "        self.indices = np.genfromtxt(f'data/lspset_dataset/{split}_indices.csv', delimiter=\",\").astype(int)\n",
    "        data = torch.from_numpy(scipy.io.loadmat('data/lspset_dataset/joints.mat')['joints'])\n",
    "        data = data.permute(2, 0, 1)\n",
    "        self.joints = data[:, :, :2].reshape(-1, 28)\n",
    "        self.occlusion_mask = data[:, :, 2].unsqueeze(-1).expand((-1, 14, 2)).reshape(-1, 28)\n",
    "        self.transform = transform = transforms.Compose(\n",
    "            [transforms.Resize((220, 220)),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index]\n",
    "        old_image = Image.open(f'data/lspset_dataset/images/im{index+1:05d}.jpg')\n",
    "        old_width, old_height = old_image.size\n",
    "        image = self.transform(old_image)\n",
    "        \n",
    "        joints = self.joints[index, :]\n",
    "        # Make joints in image square 220x220\n",
    "        joints[0:28:2] *= 220 / old_width\n",
    "        joints[1:28:2] *= 220 / old_height \n",
    "        # Make joints between [0,1]\n",
    "        joints /= 220\n",
    "        sample = {'image': image, 'joints':  joints, \n",
    "                  'occlusion_mask': self.occlusion_mask[index, :]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# from data import Dataset\n",
    "train_loader = torch.utils.data.DataLoader(Dataset('train'), batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(Dataset('test'), batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(train_loader):\n",
    "#     input = batch['image'].permute(0,2,3,1) # torch.Size([32, 220, 220, 3])\n",
    "#     targets = batch['joints'] # torch.Size([32, 28])\n",
    "#     mask = batch['occlusion_mask'] # torch.Size([32, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,96,11,4,padding=(4,4))\n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(96,256,5, padding=(2,2))\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(256,384,3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(384,384,3, padding=(1,1))\n",
    "        self.conv5 = nn.Conv2d(384,256,3)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256 * 5 * 5, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2*14)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "#         print('1: ', x.shape)\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "#         print('2: ', x.shape)\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "#         print('3: ', x.shape)\n",
    "        x = F.relu(self.conv4(x))\n",
    "#         print('4: ', x.shape)\n",
    "        x = F.relu(self.conv5(x))\n",
    "#         print('5: ', x.shape)\n",
    "        x = self.pool5(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, 256 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        input = batch['image'] # torch.Size([32, 3, 220, 220])\n",
    "        target = batch['joints'].float() # torch.Size([32, 28])\n",
    "        mask = batch['occlusion_mask'].float() # torch.Size([32, 28])\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            mask = mask.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output * mask, target * mask)\n",
    "        losses.update(loss)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n"
     ]
    }
   ],
   "source": [
    "global args, best_prec1\n",
    "args = parser.parse_args({})\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "if args.gpu is not None:\n",
    "    warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                  'disable data parallelism.')\n",
    "    torch.device(\"cuda:\"+ str(args.gpu))\n",
    "    \n",
    "# args.distributed = args.world_size > 1\n",
    "\n",
    "# if args.distributed:\n",
    "#     dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "#                             world_size=args.world_size)\n",
    "\n",
    "# create model\n",
    "# if args.pretrained:\n",
    "#     print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "#     model = models.__dict__[args.arch](pretrained=True)\n",
    "# else:\n",
    "print(\"creating model...\")\n",
    "model = Net()\n",
    "\n",
    "if args.gpu is not None:\n",
    "#     model = model.to(\"cuda:\"+ str(args.gpu))\n",
    "    model = model.cuda()\n",
    "    \n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.MSELoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/250]\tTime 0.327 (0.327)\tData 0.307 (0.307)\tLoss 0.2251 (0.2251)\t\n",
      "Epoch: [0][25/250]\tTime 0.031 (0.070)\tData 0.003 (0.049)\tLoss 0.0308 (0.0970)\t\n",
      "Epoch: [0][50/250]\tTime 0.108 (0.067)\tData 0.091 (0.045)\tLoss 0.0236 (0.0623)\t\n",
      "Epoch: [0][75/250]\tTime 0.030 (0.066)\tData 0.002 (0.044)\tLoss 0.0226 (0.0503)\t\n",
      "Epoch: [0][100/250]\tTime 0.088 (0.065)\tData 0.071 (0.043)\tLoss 0.0258 (0.0439)\t\n",
      "Epoch: [0][125/250]\tTime 0.029 (0.065)\tData 0.003 (0.043)\tLoss 0.0252 (0.0401)\t\n",
      "Epoch: [0][150/250]\tTime 0.090 (0.065)\tData 0.075 (0.043)\tLoss 0.0255 (0.0375)\t\n",
      "Epoch: [0][175/250]\tTime 0.031 (0.065)\tData 0.003 (0.043)\tLoss 0.0258 (0.0356)\t\n",
      "Epoch: [0][200/250]\tTime 0.097 (0.065)\tData 0.077 (0.043)\tLoss 0.0232 (0.0342)\t\n",
      "Epoch: [0][225/250]\tTime 0.031 (0.064)\tData 0.004 (0.043)\tLoss 0.0191 (0.0331)\t\n",
      "Epoch: [1][0/250]\tTime 0.360 (0.360)\tData 0.343 (0.343)\tLoss 0.0255 (0.0255)\t\n",
      "Epoch: [1][25/250]\tTime 0.031 (0.070)\tData 0.005 (0.048)\tLoss 0.0283 (0.0244)\t\n",
      "Epoch: [1][50/250]\tTime 0.104 (0.067)\tData 0.087 (0.045)\tLoss 0.0254 (0.0240)\t\n",
      "Epoch: [1][75/250]\tTime 0.028 (0.065)\tData 0.003 (0.043)\tLoss 0.0224 (0.0238)\t\n",
      "Epoch: [1][100/250]\tTime 0.085 (0.065)\tData 0.067 (0.043)\tLoss 0.0238 (0.0238)\t\n",
      "Epoch: [1][125/250]\tTime 0.030 (0.065)\tData 0.003 (0.043)\tLoss 0.0195 (0.0235)\t\n",
      "Epoch: [1][150/250]\tTime 0.077 (0.064)\tData 0.060 (0.043)\tLoss 0.0231 (0.0234)\t\n",
      "Epoch: [1][175/250]\tTime 0.031 (0.064)\tData 0.003 (0.042)\tLoss 0.0242 (0.0232)\t\n",
      "Epoch: [1][200/250]\tTime 0.093 (0.064)\tData 0.076 (0.042)\tLoss 0.0194 (0.0230)\t\n",
      "Epoch: [1][225/250]\tTime 0.030 (0.063)\tData 0.002 (0.041)\tLoss 0.0196 (0.0227)\t\n",
      "Epoch: [2][0/250]\tTime 0.367 (0.367)\tData 0.349 (0.349)\tLoss 0.0191 (0.0191)\t\n",
      "Epoch: [2][25/250]\tTime 0.077 (0.072)\tData 0.061 (0.052)\tLoss 0.0237 (0.0207)\t\n",
      "Epoch: [2][50/250]\tTime 0.047 (0.066)\tData 0.029 (0.047)\tLoss 0.0206 (0.0207)\t\n",
      "Epoch: [2][75/250]\tTime 0.030 (0.065)\tData 0.002 (0.045)\tLoss 0.0182 (0.0206)\t\n",
      "Epoch: [2][100/250]\tTime 0.094 (0.065)\tData 0.075 (0.045)\tLoss 0.0196 (0.0205)\t\n",
      "Epoch: [2][125/250]\tTime 0.030 (0.064)\tData 0.002 (0.043)\tLoss 0.0250 (0.0206)\t\n",
      "Epoch: [2][150/250]\tTime 0.086 (0.063)\tData 0.069 (0.042)\tLoss 0.0195 (0.0207)\t\n",
      "Epoch: [2][175/250]\tTime 0.030 (0.063)\tData 0.002 (0.042)\tLoss 0.0178 (0.0205)\t\n",
      "Epoch: [2][200/250]\tTime 0.105 (0.063)\tData 0.090 (0.042)\tLoss 0.0178 (0.0206)\t\n",
      "Epoch: [2][225/250]\tTime 0.031 (0.063)\tData 0.003 (0.042)\tLoss 0.0189 (0.0206)\t\n",
      "Epoch: [3][0/250]\tTime 0.368 (0.368)\tData 0.351 (0.351)\tLoss 0.0206 (0.0206)\t\n",
      "Epoch: [3][25/250]\tTime 0.031 (0.073)\tData 0.003 (0.053)\tLoss 0.0199 (0.0198)\t\n",
      "Epoch: [3][50/250]\tTime 0.113 (0.069)\tData 0.096 (0.047)\tLoss 0.0167 (0.0203)\t\n",
      "Epoch: [3][75/250]\tTime 0.031 (0.066)\tData 0.003 (0.045)\tLoss 0.0252 (0.0202)\t\n",
      "Epoch: [3][100/250]\tTime 0.116 (0.065)\tData 0.099 (0.044)\tLoss 0.0165 (0.0200)\t\n",
      "Epoch: [3][125/250]\tTime 0.029 (0.064)\tData 0.003 (0.043)\tLoss 0.0204 (0.0200)\t\n",
      "Epoch: [3][150/250]\tTime 0.084 (0.065)\tData 0.066 (0.043)\tLoss 0.0220 (0.0200)\t\n",
      "Epoch: [3][175/250]\tTime 0.030 (0.064)\tData 0.005 (0.042)\tLoss 0.0199 (0.0200)\t\n",
      "Epoch: [3][200/250]\tTime 0.030 (0.063)\tData 0.004 (0.042)\tLoss 0.0177 (0.0200)\t\n",
      "Epoch: [3][225/250]\tTime 0.077 (0.063)\tData 0.061 (0.042)\tLoss 0.0142 (0.0199)\t\n",
      "Epoch: [4][0/250]\tTime 0.327 (0.327)\tData 0.310 (0.310)\tLoss 0.0194 (0.0194)\t\n",
      "Epoch: [4][25/250]\tTime 0.028 (0.068)\tData 0.013 (0.051)\tLoss 0.0229 (0.0196)\t\n",
      "Epoch: [4][50/250]\tTime 0.103 (0.066)\tData 0.087 (0.047)\tLoss 0.0149 (0.0194)\t\n",
      "Epoch: [4][75/250]\tTime 0.073 (0.063)\tData 0.054 (0.045)\tLoss 0.0207 (0.0198)\t\n",
      "Epoch: [4][100/250]\tTime 0.031 (0.063)\tData 0.003 (0.043)\tLoss 0.0242 (0.0197)\t\n",
      "Epoch: [4][125/250]\tTime 0.085 (0.063)\tData 0.068 (0.043)\tLoss 0.0221 (0.0197)\t\n",
      "Epoch: [4][150/250]\tTime 0.031 (0.063)\tData 0.003 (0.042)\tLoss 0.0222 (0.0195)\t\n",
      "Epoch: [4][175/250]\tTime 0.093 (0.063)\tData 0.076 (0.042)\tLoss 0.0179 (0.0194)\t\n",
      "Epoch: [4][200/250]\tTime 0.032 (0.063)\tData 0.004 (0.042)\tLoss 0.0185 (0.0194)\t\n",
      "Epoch: [4][225/250]\tTime 0.101 (0.063)\tData 0.084 (0.041)\tLoss 0.0176 (0.0194)\t\n",
      "Epoch: [5][0/250]\tTime 0.340 (0.340)\tData 0.322 (0.322)\tLoss 0.0197 (0.0197)\t\n",
      "Epoch: [5][25/250]\tTime 0.030 (0.070)\tData 0.005 (0.051)\tLoss 0.0178 (0.0185)\t\n",
      "Epoch: [5][50/250]\tTime 0.090 (0.066)\tData 0.074 (0.047)\tLoss 0.0189 (0.0188)\t\n",
      "Epoch: [5][75/250]\tTime 0.100 (0.065)\tData 0.084 (0.046)\tLoss 0.0160 (0.0187)\t\n",
      "Epoch: [5][100/250]\tTime 0.030 (0.064)\tData 0.003 (0.044)\tLoss 0.0212 (0.0190)\t\n",
      "Epoch: [5][125/250]\tTime 0.126 (0.064)\tData 0.107 (0.044)\tLoss 0.0176 (0.0191)\t\n",
      "Epoch: [5][150/250]\tTime 0.031 (0.064)\tData 0.004 (0.043)\tLoss 0.0200 (0.0190)\t\n",
      "Epoch: [5][175/250]\tTime 0.101 (0.064)\tData 0.082 (0.044)\tLoss 0.0172 (0.0190)\t\n",
      "Epoch: [5][200/250]\tTime 0.031 (0.064)\tData 0.003 (0.043)\tLoss 0.0200 (0.0191)\t\n",
      "Epoch: [5][225/250]\tTime 0.109 (0.064)\tData 0.091 (0.043)\tLoss 0.0195 (0.0190)\t\n",
      "Epoch: [6][0/250]\tTime 0.353 (0.353)\tData 0.335 (0.335)\tLoss 0.0195 (0.0195)\t\n",
      "Epoch: [6][25/250]\tTime 0.028 (0.069)\tData 0.004 (0.048)\tLoss 0.0190 (0.0183)\t\n",
      "Epoch: [6][50/250]\tTime 0.095 (0.065)\tData 0.079 (0.045)\tLoss 0.0217 (0.0185)\t\n",
      "Epoch: [6][75/250]\tTime 0.051 (0.063)\tData 0.033 (0.044)\tLoss 0.0203 (0.0187)\t\n",
      "Epoch: [6][100/250]\tTime 0.049 (0.063)\tData 0.033 (0.044)\tLoss 0.0181 (0.0188)\t\n",
      "Epoch: [6][125/250]\tTime 0.075 (0.062)\tData 0.058 (0.043)\tLoss 0.0177 (0.0188)\t\n",
      "Epoch: [6][150/250]\tTime 0.030 (0.063)\tData 0.004 (0.043)\tLoss 0.0173 (0.0186)\t\n",
      "Epoch: [6][175/250]\tTime 0.095 (0.062)\tData 0.077 (0.042)\tLoss 0.0216 (0.0186)\t\n",
      "Epoch: [6][200/250]\tTime 0.031 (0.062)\tData 0.003 (0.041)\tLoss 0.0185 (0.0186)\t\n",
      "Epoch: [6][225/250]\tTime 0.116 (0.062)\tData 0.097 (0.041)\tLoss 0.0207 (0.0187)\t\n",
      "Epoch: [7][0/250]\tTime 0.350 (0.350)\tData 0.333 (0.333)\tLoss 0.0163 (0.0163)\t\n",
      "Epoch: [7][25/250]\tTime 0.031 (0.070)\tData 0.003 (0.049)\tLoss 0.0186 (0.0183)\t\n",
      "Epoch: [7][50/250]\tTime 0.080 (0.066)\tData 0.063 (0.045)\tLoss 0.0197 (0.0178)\t\n",
      "Epoch: [7][75/250]\tTime 0.028 (0.064)\tData 0.002 (0.043)\tLoss 0.0169 (0.0179)\t\n",
      "Epoch: [7][100/250]\tTime 0.104 (0.065)\tData 0.089 (0.044)\tLoss 0.0201 (0.0182)\t\n",
      "Epoch: [7][125/250]\tTime 0.031 (0.064)\tData 0.005 (0.043)\tLoss 0.0204 (0.0180)\t\n",
      "Epoch: [7][150/250]\tTime 0.088 (0.063)\tData 0.073 (0.043)\tLoss 0.0183 (0.0181)\t\n",
      "Epoch: [7][175/250]\tTime 0.118 (0.063)\tData 0.100 (0.043)\tLoss 0.0155 (0.0181)\t\n",
      "Epoch: [7][200/250]\tTime 0.030 (0.063)\tData 0.004 (0.042)\tLoss 0.0158 (0.0182)\t\n",
      "Epoch: [7][225/250]\tTime 0.070 (0.063)\tData 0.052 (0.042)\tLoss 0.0207 (0.0182)\t\n",
      "Epoch: [8][0/250]\tTime 0.353 (0.353)\tData 0.336 (0.336)\tLoss 0.0168 (0.0168)\t\n",
      "Epoch: [8][25/250]\tTime 0.078 (0.071)\tData 0.063 (0.053)\tLoss 0.0188 (0.0171)\t\n",
      "Epoch: [8][50/250]\tTime 0.031 (0.066)\tData 0.014 (0.048)\tLoss 0.0174 (0.0170)\t\n",
      "Epoch: [8][75/250]\tTime 0.080 (0.064)\tData 0.065 (0.046)\tLoss 0.0157 (0.0173)\t\n",
      "Epoch: [8][100/250]\tTime 0.039 (0.063)\tData 0.021 (0.045)\tLoss 0.0223 (0.0175)\t\n",
      "Epoch: [8][125/250]\tTime 0.090 (0.063)\tData 0.073 (0.045)\tLoss 0.0155 (0.0175)\t\n",
      "Epoch: [8][150/250]\tTime 0.030 (0.062)\tData 0.005 (0.044)\tLoss 0.0164 (0.0175)\t\n",
      "Epoch: [8][175/250]\tTime 0.031 (0.062)\tData 0.003 (0.044)\tLoss 0.0164 (0.0176)\t\n",
      "Epoch: [8][200/250]\tTime 0.102 (0.063)\tData 0.083 (0.044)\tLoss 0.0179 (0.0177)\t\n",
      "Epoch: [8][225/250]\tTime 0.031 (0.062)\tData 0.003 (0.043)\tLoss 0.0146 (0.0177)\t\n",
      "Epoch: [9][0/250]\tTime 0.363 (0.363)\tData 0.347 (0.347)\tLoss 0.0178 (0.0178)\t\n",
      "Epoch: [9][25/250]\tTime 0.090 (0.072)\tData 0.073 (0.053)\tLoss 0.0178 (0.0175)\t\n",
      "Epoch: [9][50/250]\tTime 0.029 (0.066)\tData 0.003 (0.046)\tLoss 0.0185 (0.0172)\t\n",
      "Epoch: [9][75/250]\tTime 0.081 (0.065)\tData 0.066 (0.045)\tLoss 0.0164 (0.0173)\t\n",
      "Epoch: [9][100/250]\tTime 0.095 (0.063)\tData 0.078 (0.043)\tLoss 0.0166 (0.0173)\t\n",
      "Epoch: [9][125/250]\tTime 0.030 (0.064)\tData 0.004 (0.043)\tLoss 0.0178 (0.0174)\t\n",
      "Epoch: [9][150/250]\tTime 0.111 (0.064)\tData 0.094 (0.043)\tLoss 0.0160 (0.0176)\t\n",
      "Epoch: [9][175/250]\tTime 0.031 (0.064)\tData 0.004 (0.044)\tLoss 0.0170 (0.0175)\t\n",
      "Epoch: [9][200/250]\tTime 0.094 (0.064)\tData 0.079 (0.044)\tLoss 0.0167 (0.0174)\t\n",
      "Epoch: [9][225/250]\tTime 0.029 (0.064)\tData 0.003 (0.043)\tLoss 0.0191 (0.0175)\t\n",
      "Epoch: [10][0/250]\tTime 0.315 (0.315)\tData 0.297 (0.297)\tLoss 0.0171 (0.0171)\t\n",
      "Epoch: [10][25/250]\tTime 0.057 (0.069)\tData 0.039 (0.050)\tLoss 0.0151 (0.0168)\t\n",
      "Epoch: [10][50/250]\tTime 0.030 (0.064)\tData 0.004 (0.045)\tLoss 0.0149 (0.0170)\t\n",
      "Epoch: [10][75/250]\tTime 0.087 (0.064)\tData 0.071 (0.045)\tLoss 0.0153 (0.0169)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][100/250]\tTime 0.052 (0.063)\tData 0.034 (0.044)\tLoss 0.0181 (0.0169)\t\n",
      "Epoch: [10][125/250]\tTime 0.031 (0.062)\tData 0.003 (0.043)\tLoss 0.0185 (0.0169)\t\n",
      "Epoch: [10][150/250]\tTime 0.095 (0.063)\tData 0.077 (0.043)\tLoss 0.0155 (0.0168)\t\n",
      "Epoch: [10][175/250]\tTime 0.031 (0.063)\tData 0.003 (0.043)\tLoss 0.0183 (0.0168)\t\n",
      "Epoch: [10][200/250]\tTime 0.095 (0.063)\tData 0.077 (0.043)\tLoss 0.0175 (0.0168)\t\n",
      "Epoch: [10][225/250]\tTime 0.031 (0.063)\tData 0.004 (0.043)\tLoss 0.0156 (0.0169)\t\n",
      "Epoch: [11][0/250]\tTime 0.346 (0.346)\tData 0.329 (0.329)\tLoss 0.0155 (0.0155)\t\n",
      "Epoch: [11][25/250]\tTime 0.094 (0.069)\tData 0.077 (0.051)\tLoss 0.0159 (0.0167)\t\n",
      "Epoch: [11][50/250]\tTime 0.030 (0.065)\tData 0.005 (0.048)\tLoss 0.0217 (0.0165)\t\n",
      "Epoch: [11][75/250]\tTime 0.077 (0.064)\tData 0.060 (0.045)\tLoss 0.0177 (0.0165)\t\n",
      "Epoch: [11][100/250]\tTime 0.031 (0.065)\tData 0.003 (0.045)\tLoss 0.0170 (0.0164)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-18-36e33e179367>\", line 37, in __getitem__\n",
      "    image = self.transform(old_image)\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 83, in to_tensor\n",
      "    return img.float().div(255)\n",
      "KeyboardInterrupt\n",
      "Process Process-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in default_collate\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in <dictcomp>\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n",
      "  File \"/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c8a00d1bf21b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     # evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-98d647d639eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if args.evaluate:\n",
    "#     validate(val_loader, model, criterion)\n",
    "#     return\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "#     if args.distributed:\n",
    "#         train_sampler.set_epoch(epoch)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "#     # evaluate on validation set\n",
    "#     prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "#     # remember best prec@1 and save checkpoint\n",
    "#     is_best = prec1 > best_prec1\n",
    "#     best_prec1 = max(prec1, best_prec1)\n",
    "#     save_checkpoint({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'arch': args.arch,\n",
    "#         'state_dict': model.state_dict(),\n",
    "#         'best_prec1': best_prec1,\n",
    "#         'optimizer' : optimizer.state_dict(),\n",
    "#     }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                input = input.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                       i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data loading code\n",
    "# traindir = os.path.join(args.data, 'train')\n",
    "# valdir = os.path.join(args.data, 'val')\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# train_dataset = datasets.ImageFolder(\n",
    "#     traindir,\n",
    "#     transforms.Compose([\n",
    "#         transforms.Resize(220),\n",
    "# #         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ]))\n",
    "\n",
    "# # if args.distributed:\n",
    "# #     train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "# # else:\n",
    "# train_sampler = None\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "#     num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.ImageFolder(valdir, transforms.Compose([\n",
    "#         transforms.Resize(220),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ])),\n",
    "#     batch_size=args.batch_size, shuffle=False,\n",
    "#     num_workers=args.workers, pin_memory=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
